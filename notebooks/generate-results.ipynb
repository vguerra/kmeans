{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing dario's implementation with pyspark\n",
    "\n",
    "# DARIO\n",
    "# (PythonRDD[352] at RDD at PythonRDD.scala:53, 97.34621969415684, 10)\n",
    "# ./launch-local-pyspark.sh kmeans-dario-x.py  27.60s user 3.99s system 193% cpu 16.317 total\n",
    "\n",
    "# MINE\n",
    "# Step, Error\n",
    "# 1, 207.005191339\n",
    "# 2, 136.146896296\n",
    "# 3, 101.422771741\n",
    "# 4, 97.6294436311\n",
    "# 5, 97.3907745325\n",
    "# 6, 97.3259242343\n",
    "# Final error: 97.3259242343 achieved on 6 steps\n",
    "# ./launch-local-pyspark-kmeans.sh ./input/iris.data.txt 3 4 parallel 0.0001  12.81s user 1.15s system 276% cpu 5.053 total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All configuration options\n",
    "\n",
    "# datasets\n",
    "datasets = [\n",
    "    {\n",
    "        'name': 'Iris Dataset',\n",
    "        'path': './input/iris.data.txt',\n",
    "        'features': 4,\n",
    "        'clusters': 3,\n",
    "        'epsilon': 1e-4\n",
    "    },\n",
    "    {\n",
    "        'name': 'Spam Dataset',\n",
    "        'path': './input/spambase.data.txt',\n",
    "        'features': 57,\n",
    "        'clusters': 30,\n",
    "        'epsilon': 100\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        'name': 'synthetic 5000',\n",
    "        'path': './input/synthetic-5000-15.data.txt',\n",
    "        'features': 15,\n",
    "        'clusters': 10,\n",
    "        'epsilon': 0.1\n",
    "    }\n",
    "]\n",
    "\n",
    "# Kmeans initialization modes supported\n",
    "init_modes = [\"random\", \"parallel\"]\n",
    "\n",
    "# scala flavors of KMeans\n",
    "scala_impl_types = [\"rdd\", \"dataset\", \"dataframe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: Iris Dataset\n",
      "time ./launch-local-pyspark-kmeans.sh ./input/iris.data.txt 3 4 random 0.0001\n",
      "time ./scala/launch-local-spark.sh ./input/iris.data.txt 3 4 random rdd 0.0001\n",
      "time ./scala/launch-local-spark.sh ./input/iris.data.txt 3 4 random dataset 0.0001\n",
      "time ./scala/launch-local-spark.sh ./input/iris.data.txt 3 4 random dataframe 0.0001\n",
      "time ./launch-local-pyspark-kmeans.sh ./input/iris.data.txt 3 4 parallel 0.0001\n",
      "time ./scala/launch-local-spark.sh ./input/iris.data.txt 3 4 parallel rdd 0.0001\n",
      "time ./scala/launch-local-spark.sh ./input/iris.data.txt 3 4 parallel dataset 0.0001\n",
      "time ./scala/launch-local-spark.sh ./input/iris.data.txt 3 4 parallel dataframe 0.0001\n",
      "\n",
      "DATASET: Spam Dataset\n",
      "time ./launch-local-pyspark-kmeans.sh ./input/spambase.data.txt 30 57 random 100\n",
      "time ./scala/launch-local-spark.sh ./input/spambase.data.txt 30 57 random rdd 100\n",
      "time ./scala/launch-local-spark.sh ./input/spambase.data.txt 30 57 random dataset 100\n",
      "time ./scala/launch-local-spark.sh ./input/spambase.data.txt 30 57 random dataframe 100\n",
      "time ./launch-local-pyspark-kmeans.sh ./input/spambase.data.txt 30 57 parallel 100\n",
      "time ./scala/launch-local-spark.sh ./input/spambase.data.txt 30 57 parallel rdd 100\n",
      "time ./scala/launch-local-spark.sh ./input/spambase.data.txt 30 57 parallel dataset 100\n",
      "time ./scala/launch-local-spark.sh ./input/spambase.data.txt 30 57 parallel dataframe 100\n",
      "\n",
      "DATASET: synthetic 5000\n",
      "time ./launch-local-pyspark-kmeans.sh ./input/synthetic-5000-15.data.txt 10 15 random 0.1\n",
      "time ./scala/launch-local-spark.sh ./input/synthetic-5000-15.data.txt 10 15 random rdd 0.1\n",
      "time ./scala/launch-local-spark.sh ./input/synthetic-5000-15.data.txt 10 15 random dataset 0.1\n",
      "time ./scala/launch-local-spark.sh ./input/synthetic-5000-15.data.txt 10 15 random dataframe 0.1\n",
      "time ./launch-local-pyspark-kmeans.sh ./input/synthetic-5000-15.data.txt 10 15 parallel 0.1\n",
      "time ./scala/launch-local-spark.sh ./input/synthetic-5000-15.data.txt 10 15 parallel rdd 0.1\n",
      "time ./scala/launch-local-spark.sh ./input/synthetic-5000-15.data.txt 10 15 parallel dataset 0.1\n",
      "time ./scala/launch-local-spark.sh ./input/synthetic-5000-15.data.txt 10 15 parallel dataframe 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Collecting Python data\n",
    "for dataset in datasets:\n",
    "    print(\"DATASET: %s\" % dataset['name'])\n",
    "    for init_mode in init_modes:\n",
    "        print(\"time ./launch-local-pyspark-kmeans.sh %s %s %s %s %s\" % (\n",
    "            dataset['path'], dataset['clusters'], dataset['features'], init_mode, dataset['epsilon']\n",
    "        ))\n",
    "        for scala_impl_type in scala_impl_types:\n",
    "            print(\"time ./scala/launch-local-spark.sh %s %s %s %s %s %s\" % (\n",
    "            dataset['path'], dataset['clusters'], dataset['features'], init_mode, scala_impl_type, dataset['epsilon']\n",
    "            ))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph(dataset, clusters, features, data_for_graphs):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_syn5000_10_15_random = [7, 18506.833943]\n",
    "scala_syn5000_10_15_random_rdd = [3, 18662.746]\n",
    "scala_syn5000_10_15_random_dataset = [3, 18619.31]\n",
    "scala_syn5000_10_15_random_dataframe = [2, 18751.445]\n",
    "python_syn5000_10_15_parallel = [9, 18631.3789046]\n",
    "scala_syn5000_10_15_parallel_rdd = [1, 19008.086]\n",
    "scala_syn5000_10_15_parallel_dataset = [1, 19031.938]\n",
    "scala_syn5000_10_15_parallel_datafrarme = [1, 19031.545]\n",
    "data_for_graphs = [\n",
    "    ('random', 'pyspark' python_syn5000_10_15_random),\n",
    "    ('random', 'scala-rdd', scala_syn5000_10_15_random_rdd),\n",
    "    ('rarndom', 'scala-dataset' scala_syn5000_10_15_random_dataset),\n",
    "    ('random', 'scala-dataframe', scala_syn5000_10_15_random_dataframe),\n",
    "    ('parallel', 'pyspark' python_syn5000_10_15_parallel),\n",
    "    ('parallel', 'scala-rdd', scala_syn5000_10_15_parallel_rdd),\n",
    "    ('parallel', 'scala-dataset' scala_syn5000_10_15_parallel_dataset),\n",
    "    ('parallel', 'scala-dataframe', scala_syn5000_10_15_parallel_dataframe)\n",
    "]\n",
    "\n",
    "generate_graph('Spam', 5, 57, data_for_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_spam_30_57_random = [14, 218007.459118]\n",
    "scala_spam_30_57_random_rdd = [62, 171111.73]\n",
    "scala_spam_30_57_random_dataset = [65, 178050.78]\n",
    "scala_spam_30_57_random_dataframe = [44, 174026.81]\n",
    "python_spam_30_57_parallel = [4, 198670.599216]\n",
    "scala_spam_30_57_parallel_rdd = [3, 231058.062749]\n",
    "scala_spam_30_57_parallel_dataset = [7, 140632.0]\n",
    "scala_spam_30_57_parallel_datafrarme = [5, 150223.22]\n",
    "data_for_graphs = [\n",
    "    ('random', 'pyspark' python_spam_5_57_random),\n",
    "    ('random', 'scala-rdd', scala_spam_5_57_random_rdd),\n",
    "    ('rarndom', 'scala-dataset' scala_spam_5_57_random_dataset),\n",
    "    ('random', 'scala-dataframe', scala_spam_5_57_random_dataframe),\n",
    "    ('parallel', 'pyspark' python_spam_5_57_parallel),\n",
    "    ('parallel', 'scala-rdd', scala_spam_5_57_parallel_rdd),\n",
    "    ('parallel', 'scala-dataset' scala_spam_5_57_parallel_dataset),\n",
    "    ('parallel', 'scala-dataframe', scala_spam_5_57_parallel_dataframe)\n",
    "]\n",
    "\n",
    "generate_graph('Spam', 5, 57, data_for_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_iris_3_4_random = [6, 97.3259242343]\n",
    "scala_iris_3_4_random_rdd = [5, 97.32591]\n",
    "scala_iris_3_4_random_dataset = [12, 97.346214]\n",
    "scala_iris_3_4_random_dataframe = [14, 97.346214]\n",
    "python_iris_3_4_parallel = [3, 97.346214]\n",
    "scala_iris_3_4_parallel_rdd = [5, 97.346214]\n",
    "scala_iris_3_4_parallel_dataset = [2, 97.346214]\n",
    "scala_iris_3_4_parallel_datafrarme = 2, 97.346214]\n",
    "\n",
    "data_for_graphs = [\n",
    "    ('random', 'pyspark' python_iris_3_4_random),\n",
    "    ('random', 'scala-rdd', scala_iris_3_4_random_rdd),\n",
    "    ('rarndom', 'scala-dataset' scala_iris_3_4_random_dataset),\n",
    "    ('random', 'scala-dataframe', scala_iris_3_4_random_dataframe),\n",
    "    ('parallel', 'pyspark' python_iris_3_4_parallel),\n",
    "    ('parallel', 'scala-rdd', scala_iris_3_4_parallel_rdd),\n",
    "    ('parallel', 'scala-dataset' scala_iris_3_4_parallel_dataset),\n",
    "    ('parallel', 'scala-dataframe', scala_iris_3_4_parallel_dataframe)\n",
    "]\n",
    "\n",
    "generate_graph('Iris',3, 4, data_for_graphs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
